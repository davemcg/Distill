---
title: "R Notebook"
output: html_notebook
---

```{bash, eval=F}
time gemini query --header -q "SELECT * from variants WHERE (aaf_esp_all < 0.01 AND aaf_1kg_all_float < 0.01 AND af_exac_all < 0.01  AND (is_coding=1 OR is_splicing=1)) OR impact_severity='HIGH' OR clinvar_sig LIKE '%patho%'" clinvar_RD.PED_faux.gemini.db | bgzip > clinvar.gemini.tsv.gz
```

Load output from gemini
```{r}
library(here)
library(tidyverse)
library(data.table)
clinvar <- fread(paste0('gzcat ', here('processed_data/clinvar.gemini.tsv.gz')))
```

# Count pathogenic, benign, and benign (in RD cases) variants
```{r}
clinvar %>% group_by(status) %>% summarise(Count=n())
```

# Predictors available
```{r}
colnames(clinvar)
```

# Which predictors are character? 
And may need some extra prep help
```{r}
clinvar %>% select_if(is.character) %>% colnames()
```

# Prep data for modeling
```{r}

clinvar_processed <- clinvar %>% 
  separate(gene_eyediseaseclass, c('RDGene','DiseaseClass'), sep='_') %>%  #split off RD disease type
  select(-RDGene) %>% 
  mutate(impact_severity = case_when(impact_severity == 'HIGH' ~ 3, # convert to integer 
                                      impact_severity == 'MED' ~ 2, 
                                      TRUE ~ 1),
         Status = case_when(status=='PATHOGENIC_RD' ~ 'Pathogenic',
                            TRUE ~ 'NotPathogenic'),
         genesplicer = case_when(genesplicer == "" ~ 'No',
                                 grepl('^gain', genesplicer) ~ 'Gain',
                                 grepl('^loss', genesplicer) ~ 'Loss',
                                 grepl('^diff', genesplicer) ~ 'Diff',
                                 TRUE ~ 'Else')) %>% 
  mutate(Status = factor(Status, levels=c('Pathogenic','NotPathogenic'))) %>% 
  mutate_at(vars(matches('ac_|an_|^n_')), funs(as.integer(.))) %>% # convert columns with ac_|whatever to integer (ac is allele count)
  mutate_at(vars(matches('af_|dann|revel|mpc|gerp|polyphen_score|sift_score|fitcons_float|gerp_elements|^adj|_z$|^pli$|^pnull$|precessive|^phylop_100')), funs(as.numeric(.))) %>%  # af is allele frequency
select(variant_id, Status, is_exonic, is_coding, is_lof, is_splicing, impact_severity, polyphen_score, sift_score, dann, gerp, DiseaseClass, mpc, revel, aaf_1kg_afr_float:an_exac_sas, fitcons_float, gno_ac_afr:gno_an_popmax, lof_z:precessive, phylop_100way, grantham, maxentscan, cadd_phred, fathmm_mkl_coding_score, genesplicer, spliceregion)

clinvar_processed[is.na(clinvar_processed)] <- -1

all_PATH <- clinvar_processed %>% 
  filter(Status == 'Pathogenic') %>% 
  unique()
all_NOT_PATH <- clinvar_processed %>% 
  filter(Status != 'Pathogenic') %>% 
  unique()

all_set <- clinvar_processed

all_PATH <- all_set %>% filter(Status=='Pathogenic')
# cut down pathogenic to 5x of path
set.seed(115470)
all_NOT_PATH__CUT <- all_set %>% filter(Status=='NotPathogenic', max_aaf_all < 0.02) %>% sample_n(nrow(all_PATH) * 5)

ML_set <- rbind(all_PATH, all_NOT_PATH__CUT)
```


## One hot encoding (Dummy variables)
Turn categorical factors into variables

Many ML algorithms can't handle factor

You can feed this into the `Train and Test sets` section below if you are using something like a GLM or NN. 

```{r, eval = F}
library(dummies)
temp <- ML_set %>% dplyr::select(-Status)
temp <- dummy.data.frame(temp, sep='_')
ML_set_dummy <- temp %>% mutate(Status = ML_set$Status)
# recreate for full data
temp <- all_set %>% dplyr::select(-Status)
temp <- dummy.data.frame(temp, sep='_')
all_dummy <- temp %>% mutate(Status = all_set$Status)
```

## Train and Validate and Test sets
Split in training / validating / testing

```{r}
set.seed(115470)
train_set <- ML_set_dummy %>% 
  group_by(Status) %>% 
 # filter(!Complicated_Status=='Comp_Het') %>% # remove comp hets for now
  sample_frac(0.33) %>% ungroup()
# remove no variance columns
#var_columns <- colnames(train_set)[apply(train_set, MARGIN = 2, function(x) var(x) > 0)]
#var_columns <- var_columns[!is.na(var_columns)]
#train_set <- train_set[,c(var_columns, 'Status', 'Complicated_Status')]

set.seed(115470)
validate_set <- ML_set_dummy %>% 
  filter(!variant_id %in% train_set$variant_id) %>% 
  group_by(Status) %>% 
  sample_frac(0.5) %>% ungroup()

test_set <- ML_set_dummy %>% 
  filter(!variant_id %in% c(train_set$variant_id, validate_set$variant_id))
# remove no variance columns
#var_columns <- colnames(test_set)[apply(test_set, MARGIN = 2, function(x) var(x) > 0)]
#var_columns <- var_columns[!is.na(var_columns)]
#test_set <- test_set[,c(var_columns, 'Status', 'Complicated_Status')]
```

# Model!
```{r}
library(caret)
library(mlbench)
library(parallel)
library(doParallel)
library(MLmetrics)
#library(plotROC)

# CV on rf seems to overfit
fitControl_RF <- trainControl(
  classProbs=T,
  savePredictions = T,
  allowParallel = T,
  summaryFunction = twoClassSummary)

# for the nonRF models
fitControl <- trainControl(## 5-fold CV
  method = "cv",
  number = 5,
  classProbs=T,
  savePredictions = T,
  allowParallel = T,
  summaryFunction = twoClassSummary)
cluster <- makeCluster(detectCores() - 1) # leave some cores for me!
registerDoParallel(cluster)

rfFit <- caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "rf", metric='Sens',
                      trControl = fitControl_RF)

bglmFit <- caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "bayesglm", metric='Sens',
                      trControl = fitControl)

avNNetFit <- caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "avNNet", metric='Sens',
                      trControl = fitControl)
xgbTreeFit <-caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "xgbTree",  metric='Sens',
                      trControl = fitControl)

stepLDAFit <- caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "stepLDA",  metric='Sens',
                      trControl = fitControl)
naive_bayesFit <- caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "naive_bayes",  metric='Sens',
                      trControl = fitControl)

dnnFit <- caret::train(Status ~ ., data=train_set, 
                      preProcess = c("scale", "center"),
                      method = "dnn",  metric='Sens',
                      trControl = fitControl)

my_models <- list(rfFit,bglmFit,avNNetFit, xgbTreeFit,stepLDAFit)
names(my_models) <- c('rfFit','bglmFit','avNNetFit', 'xgbTreeFit','stepLDAFit')

```

# ConfusionMatrix your model(s)
```{r}
# fuller_data is all variants, minus the variants in the test_set
fuller_data = all_dummy %>% filter(!variant_id %in% c(test_set$variant_id, train_set$variant_id))

# center scale
fuller_data_CS = preProcess(fuller_data, method = c('center','scale')) %>% predict(., fuller_data)

cm_maker <- function(model, data, cutoff=0.5) {
  new_predictions <- predict(model, data, type='prob') %>%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic > cutoff ~ 'Pathogenic', TRUE ~ 'NotPathogenic'))
  confusionMatrix(data = new_predictions$Prediction, reference = new_predictions$Answers, mode='prec_recall')
}
#example
cm_maker(bglmFit, fuller_data_CS, cutoff=0.5)
cm_maker(avNNetFit, fuller_data_CS, cutoff=0.5)
cm_maker(rfFit, fuller_data_CS, cutoff=0.5)
```

# AUC ROC
```{r, fig.width=4}
library(PRROC)

# precision recall AUC
aucroc_maker <- function(model, data, cutoff=0.5) {
  new_predictions <- predict(model, data, type = 'prob') %>%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic > cutoff ~ 'Pathogenic', TRUE ~ 'NotPathogenic'))
  pr.curve(scores.class0 = new_predictions %>% filter(Answers=='Pathogenic') %>% pull(Pathogenic),
           scores.class1 = new_predictions %>% filter(Answers=='NotPathogenic') %>% pull(Pathogenic),
           curve = T)
}

# ROC AUC
roc_maker <- function(model, data, cutoff=0.5) {
  new_predictions <- predict(model, data, type = 'prob') %>%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic > cutoff ~ 'Pathogenic', TRUE ~ 'NotPathogenic'))
  roc.curve(scores.class0 = new_predictions %>% filter(Answers=='Pathogenic') %>% pull(Pathogenic),
           scores.class1 = new_predictions %>% filter(Answers=='NotPathogenic') %>% pull(Pathogenic),
           curve = T)
}

aucroc_data <- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  out <- aucroc_maker(my_models[[i]], all_dummy)
  out <- out$curve[,1:2] %>% data.frame()
  colnames(out) <- c('Recall','Precision')
  out$model <- i
  aucroc_data <- rbind(aucroc_data, out)
}

pr <- aucroc_data %>% ggplot(aes(x=Recall, y=Precision, colour=model)) + geom_line() + theme_minimal() + ggsci::scale_color_aaas() + ggtitle('prROC')


roc_data <- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  out <- roc_maker(my_models[[i]], all_dummy)
  out <- out$curve[,1:2] %>% data.frame()
  colnames(out) <- c('FPR','Sensitivity')
  out$model <- i
  roc_data <- rbind(roc_data, out)
}

roc <- roc_data %>% ggplot(aes(x=FPR, y=Sensitivity, colour=model)) + geom_line() + theme_minimal() + ggsci::scale_color_aaas() + ggtitle('aucROC')
library(cowplot)
cowplot::plot_grid(roc, pr)
```

# Variable importance
```{r}
varImp(rfFit)
varImp(bglmFit)
```
# Notes
1. aucROC and ROC are good for the model. Too good. 
2. Whether a variant is in eyeDisease class or not is by far the most important variable

Do we have any non pathogenic variants in diseae class?
```{r}
clinvar_processed %>% group_by(Status, DiseaseClass) %>% summarise(Count=n())
```
Yes, though there is REALLY strong enrichment. 

3. I think adding the benign variants from the UK10K data will make a dramatic difference
4. Revel and Dann seem moderately useful

# SessionInfo()
```{r}
devtools::session_info()
```